{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opakování &ndash; užitečné věci z Pythonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delka stringu je: 18\n",
      "String obsahuje slova: ['to', 'be', 'Or', 'NOT', 'to', 'be']\n",
      "String obsahuje unikatni slova: {'be', 'NOT', 'Or', 'to'}\n",
      "String prevedeny na mala pismena:  to be or not to be\n",
      "Delka pole (pocet slov) je: 6\n",
      "Prvni prvek v poli je: to\n",
      "Posledni prvek v poli je: be\n"
     ]
    }
   ],
   "source": [
    "my_string = \"to be Or NOT to be\"\n",
    "my_list = my_string.split()\n",
    "print ('Delka stringu je:', len(my_string))\n",
    "print ('String obsahuje slova:', my_string.split())\n",
    "print ('String obsahuje unikatni slova:', set(my_string.split()))\n",
    "print ('String prevedeny na mala pismena: ', my_string.lower())\n",
    "print ('Delka pole (pocet slov) je:', len(my_list))\n",
    "print ('Prvni prvek v poli je:', my_list[0])\n",
    "print ('Posledni prvek v poli je:', my_list[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spuštění interaktivního shellu PySpark\n",
    "\n",
    "`export PYSPARK_PYTHON=python3`  \n",
    "`pyspark --master yarn --num-executors 2 --executor-memory 4G --conf spark.ui.port=1<ddmm>`, kde `<ddmm>` je váš den a měsíc narození, např. `spark.ui.port=10811`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úkol č. 1: rozběhání příkladu z přednášky (word count)\n",
    "\n",
    "Vyzkoušejte, že příklad z přednášky funguje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nacteni RDD\n",
    "lines = sc.textFile(\"/user/pascepet/data/bible/bible.txt\")\n",
    "\n",
    "# rozdeleni radku\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))\n",
    "\n",
    "# transformace radku na (key, value)\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "\n",
    "# secteni jednicek ke kazdemu klici\n",
    "counts = pairs.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# vypis vysledku\n",
    "counts.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úkol č. 2: vylepšení příkladu z přednášky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vylepšete skript z úkolu č. 1 o následující funkcionality:\n",
    "\n",
    "2.1. Ignorujte začátky řádků (název biblické knihy a kód kapitola:verš &ndash; jsou odděleny od textu tabulátorem).  \n",
    "2.2. Slova, která se liší jen velikostí písmen, se budou považovat za stejná.  \n",
    "2.3. Odstraňte z textu nealfanumerické znaky &ndash; všechny nebo aspoň některé z nich (např. '.', ':', '-' atd.).  \n",
    "2.4. Vyřaďte ze zpracování slova v množině tzv. *stopwords* (v souboru `/user/pascepet/data/stopwords.txt`).   \n",
    "*Hint: stopwords můžete dostat do proměnné typu set např. takto:*  \n",
    "`sw = set(sc.textFile('/user/pascepet/data/stopwords.txt').collect())`  \n",
    "2.5. Vyberte RDD, které je vhodné si pro další výpočty kešovat, a nakešujte ho.  \n",
    "2.6. Na konci seřaďte slova podle četnosti sestupně (použijte [metodu sortBy](https://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.sortBy)).  \n",
    "--> Slova mimo stopwords s nejvyšším výskytem: 'lord' 7830; 'god' 4443; 'said' 3999; 'will' 3836; 'man' 2613...  \n",
    "2.7. Najděte nejdelší slovo (s největším počtem znaků).  \n",
    "--> 'mahershalalhashbaz' (18); 'chushanrishathaim' (17); 'kibrothhattaavah' (16); 'covenantbreakers' (16); 'evilfavouredness' (16)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úkol č. 3: další analýza textu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V této části budeme pracovat s původním textem.\n",
    "\n",
    "3.1. Zjistěte počet slov v každém verši (1 verš = 1 řádek) a najděte verše s největšim a nejmenším počtem slov.  \n",
    "--> 'Esther 8:9' 87 slov; 'John 11:35' 2 slova  \n",
    "3.2. Proveďte stejný výpočet jako v 3.1, ale v každém verši počítejte jen unikátní slova (každé slovo jen jednou).  \n",
    "--> 'Esther 8:9' 57 slov; 'John 11:35' 2 slova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úkol č. 4: číselné výpočty z dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "Budeme pracovat se soubory hodinových údajů o teplotách (použili jsme ho na supercvičení Hive). Pokud jste na tomto supercvičení byli, pravděpodobně už máte data na HDFS (v podadresáři svého pracovního adresáře, jsou to soubory `teplota1-6.csv` a `teplota7-12.csv`) Zkontrolujte to.  \n",
    "Nemáte-li je tam, proveďte následující kroky:\n",
    "\n",
    "* zkopírujte soubor `/home/pascepet/fel_bigdata/data/teplota-usa.zip` do svého uživatelského adresáře (doporučuji si na to vytvořit podadresář);\n",
    "* rozbalte;\n",
    "* vytvořte na HDFS ve svém uživatelském adresáři vhodný podadresář;\n",
    "* rozbalené soubory nakopírujte na HDFS do nově vytvořeného adresáře.\n",
    "\n",
    "CSV soubor má jako oddělovač znak `','`. Také obsahuje hlavičky s názvy sloupců, které je potřeba při zpracování odstranit.    \n",
    "Teplota je uvedena v 10&times;&deg;F. Některé řádky obsahují na místě teploty prázdný řetězec, tj. údaj pro ně není k dispozici.\n",
    "\n",
    "**Sloupce:** id_stanice, mesic, den, hodina, teplota, flag, latitude, longitude, vyska, stat, nazev\n",
    "\n",
    "*Poznámka: Spark umí v metodě textFile načíst celý adresář (spojí všechny soubory v adresáři do jednoho RDD).*\n",
    "\n",
    "#### Zadání\n",
    "\n",
    "4.1. Prohlédněte si několik prvních řádků z některého souboru, abyste si připomněli, co v datech je.  \n",
    "4.2. Zjistěte, který stát ma nejvyšší průměrnou teplotu z měření jen za měsíce 6&ndash;8. Teplotu uveďte ve stupních Celsia.  \n",
    "4.3. Pro každý měsíc vypište stát, který má nejvyšší průměrnou teplotu z měření za tento měsíc.\n",
    "\n",
    "\n",
    "#### Očekávaný výstup\n",
    "\n",
    "V zadání 4.2\n",
    "\n",
    "| stat | prum_teplota |\n",
    "|------|--------------:|\n",
    "| MH   | 28.10121053814158 | \n",
    "\n",
    "\n",
    "V zadání 4.3\n",
    "\n",
    "| mesic | stat | prum_teplota |\n",
    "|-------|------|-------------:|\n",
    "| 1     | AS | 28.1482513153823|  \n",
    "| 2     | AS | 28.268547273982037|  \n",
    "| 3     | AS | 28.305594514570675|  \n",
    "| 4     | PW | 28.14697855750485|  \n",
    "| 5     | PW | 28.15864931145062|  \n",
    "| 6     | MH | 28.085874246339472|  \n",
    "| 7     | AZ | 29.07906528274055|  \n",
    "| 8     | TX | 28.335826966364785|  \n",
    "| 9     | MH | 28.220327304048165|  \n",
    "| 10     | MH | 28.22359756605796|  \n",
    "| 11     | MH | 28.125538329026583|  \n",
    "| 12     | AS | 27.996042413381048|  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
