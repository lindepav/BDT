{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Spuštění PySpark\n",
    "\n",
    "`export PYSPARK_PYTHON=python3`  \n",
    "`pyspark --master yarn --num-executors 2 --executor-memory 4G --conf spark.ui.port=1<ddmm>`, kde `<ddmm>` je váš den a měsíc narození, např. `spark.ui.port=10811`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpfull import\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1\n",
    "df = spark.read.csv('c:/code/fel/trips.txt', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.5\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.6\n",
    "df.select('route_id').distinct()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.7\n",
    "df.select('route_id').groupBy().agg({'route_id':'max','route_id':'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.8\n",
    "df_l1=df.filter(df_routes['route_id'] == 'L1')\n",
    "df_l1.groupBy('direction_id').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.9\n",
    "df_routes=spark.read.csv('c:/code/fel/routes.txt', header=True)\n",
    "df_all =df.join(df_routes, df_routes['route_id']==df['route_id'])\n",
    "df_all.filter(df_all['is_night'] == '1').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "songsDF = spark.read \\\n",
    "\t.format(\"csv\") \\\n",
    "\t.option(\"header\", \"false\") \\\n",
    "\t.option(\"delimiter\", \",\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "\t.load(\"/??/data/lyrics/lyrics.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1\n",
    "\n",
    "songsDF2 = songsDF.filter('rok>=1950 and rok<=2018')\n",
    "songsDF2.cache() # uzitecne nakesovani, aby dalsi vypocty probihaly od tohoto bodu\n",
    "songsDF2.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2\n",
    "\n",
    "songsDF2 = songsDF2.fillna('', 'text')\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('text', F.lower(songsDF2['text']))\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('text', F.regexp_replace(songsDF2['text'], '[\\W ]', ' '))\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('text', F.regexp_replace(songsDF2['text'], '[ ]+', ' '))\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('text', F.trim(songsDF2['text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4\n",
    "songsDF2 = songsDF2.withColumn('slova_poc', F.size(F.split(songsDF2['text'], ' ')))\n",
    "songsDF2.filter('text=\"\"').show()\n",
    "songsDF2 = songsDF2.withColumn('slova_poc', F.when(songsDF2['text']=='', 0).otherwise(songsDF2['slova_poc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4\n",
    "songsDF2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1\n",
    "\n",
    "interprets = songsDF2.groupBy('interpret').count() \\\n",
    "    .toDF('interpret', 'pocet').filter(\"pocet >= 500\")\n",
    "\n",
    "interprets.count()\n",
    "interprets.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 \n",
    "\n",
    "songsDF2.filter('slova_poc > 0') \\\n",
    "    .groupBy('interpret').agg({'*':'count', 'slova_poc':'avg'}) \\\n",
    "    .toDF('interpret', 'prumer', 'pocet').filter('pocet>=100') \\\n",
    "    .orderBy('prumer', ascending=False) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1\n",
    "words_top = songsDF2.rdd \\\n",
    "    .flatMap(lambda r: r[5].split(\" \")) \\\n",
    "    .filter(lambda r: len(r)>1) \\\n",
    "    .map(lambda r: (r, 1)) \\\n",
    "    .reduceByKey(lambda a,b: a+b) \\\n",
    "    .sortBy(lambda r: r[1], False)\n",
    "    \n",
    "words_top.take(20)\n",
    "\n",
    "\n",
    "stopw = sc.textFile(\"/??/data/stopwords.txt\").collect()\n",
    "stopw = set(stopw)\n",
    "\n",
    "words_top2 = songsDF2.rdd \\\n",
    "    .flatMap(lambda r: r[5].split(\" \")) \\\n",
    "    .filter(lambda r: len(r)>1) \\\n",
    "    .filter(lambda r: r not in stopw) \\\n",
    "    .map(lambda r: (r, 1)) \\\n",
    "    .reduceByKey(lambda a,b: a+b) \\\n",
    "    .sortBy(lambda r: r[1], False)\n",
    "    \n",
    "words_top2.take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('is_love', F.when(F.regexp_extract(songsDF2['text'], r'\\b(love)\\b', 1) == 'love', 1).otherwise(0))\n",
    "songsDF2 = songsDF2.withColumn('is_like', F.when(F.regexp_extract(songsDF2['text'], r'\\b(like)\\b', 1) == 'like', 1).otherwise(0))\n",
    "songsDF2 = songsDF2.withColumn('is_know', F.when(F.regexp_extract(songsDF2['text'], r'\\b(know)\\b', 1) == 'know', 1).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3\n",
    "interprets_words = interprets.join(songsDF2, 'interpret') \\\n",
    "    .select('interpret', 'is_love', 'is_like', 'is_know') \\\n",
    "    .groupBy('interpret') \\\n",
    "    .agg({'is_love':'avg', 'is_like':'avg', 'is_know':'avg'})\n",
    "\n",
    "interprets_words.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "72ce3b0a56a865d480673a9187eace210a751ef3304bdc5d2817c20bdd65e6d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
