{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Spuštění PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "export PYSPARK_PYTHON=python3\n",
    "pyspark --master yarn --num-executors 2 --executor-memory 4G --conf spark.ui.port=1<ddmm>`, kde `<ddmm>` je váš den a měsíc narození, např. `spark.ui.port=10811`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpfull import\n",
    "\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Load the file into the DataFrame (with automatic schema derivation) and assign the correct field names to the columns.\n",
    "\n",
    "df = spark.read.csv('c:/code/fel/trips.txt', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Cache the file in memory.\n",
    "\n",
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 Write out a sample of the data.\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4 Write out a basic exploration of the data.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.5 Find out the total number of records (rows) in the DataFrame. (72 530)\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.6 Find out how many unique routes are there. (816)\n",
    "\n",
    "df.select('route_id').distinct()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.7 Find out the lowest and highest route number are there. (1, 997)\n",
    "\n",
    "df.select('route_id').groupBy().agg({'route_id':'max','route_id':'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.8 Find out the number of trips for both direction for route L1. (210,211)\n",
    "\n",
    "df_l1=df.filter(df_routes['route_id'] == 'L1')\n",
    "df_l1.groupBy('direction_id').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.9 Find out a count of night trips. ()\n",
    "\n",
    "df_routes=spark.read.csv('c:/code/fel/routes.txt', header=True)\n",
    "df_all =df.join(df_routes, df_routes['route_id']==df['route_id'])\n",
    "df_all.filter(df_all['is_night'] == '1').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.10 Additionally: Create a temporary table from the DataFrame and try to do 1.5–1.8 using SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2 Exclude all records that have a year listed outside the 1950--2018 range. Determine how many records remain in the DataFrame. (362 221)\n",
    "\n",
    "songsDF = spark.read \\\n",
    "\t.format(\"csv\") \\\n",
    "\t.option(\"header\", \"false\") \\\n",
    "\t.option(\"delimiter\", \",\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "\t.load(\"/??/data/lyrics/lyrics.csv\")\n",
    "\n",
    "songsDF2 = songsDF.filter('rok>=1950 and rok<=2018')\n",
    "songsDF2.cache() # uzitecne nakesovani, aby dalsi vypocty probihaly od tohoto bodu\n",
    "songsDF2.count()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 Edit the lyrics\n",
    "\n",
    "songsDF2 = songsDF2.fillna('', 'text')\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('text', F.lower(songsDF2['text']))\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('text', F.regexp_replace(songsDF2['text'], '[\\W ]', ' '))\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('text', F.regexp_replace(songsDF2['text'], '[ ]+', ' '))\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('text', F.trim(songsDF2['text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Add a words_poc column to the DataFrame containing the number of all words in the song.\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('slova_poc', F.size(F.split(songsDF2['text'], ' ')))\n",
    "songsDF2.filter('text=\"\"').show()\n",
    "songsDF2 = songsDF2.withColumn('slova_poc', F.when(songsDF2['text']=='', 0).otherwise(songsDF2['slova_poc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4  Cache the resulting DataFrame again.\n",
    "\n",
    "songsDF2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1 Find out how many artists have at least 500 songs and who they are. Create a separate DataFrame for these artists, use it in Assignment 4.3. (19; Bob Dylan 614, Chris Brown 655, etc.)\n",
    "\n",
    "\n",
    "interprets = songsDF2.groupBy('interpret').count() \\\n",
    "    .toDF('interpret', 'pocet').filter(\"pocet >= 500\")\n",
    "\n",
    "interprets.count()\n",
    "interprets.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 Considering only songs with non-empty lyrics (i.e., word counts greater than 0), which artist with at least 100 such songs has the highest average number of words per song? (eightball-mjg 627.9)\n",
    "\n",
    "songsDF2.filter('slova_poc > 0') \\\n",
    "    .groupBy('interpret').agg({'*':'count', 'slova_poc':'avg'}) \\\n",
    "    .toDF('interpret', 'prumer', 'pocet').filter('pocet>=100') \\\n",
    "    .orderBy('prumer', ascending=False) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1  Find the 20 most frequently occurring words of at least two characters in song lyrics. (Count each word as many times as it appears in the text. Here it is useful to process the DataFrame using RDD transformations.)\n",
    "\n",
    "words_top = songsDF2.rdd \\\n",
    "    .flatMap(lambda r: r[5].split(\" \")) \\\n",
    "    .filter(lambda r: len(r)>1) \\\n",
    "    .map(lambda r: (r, 1)) \\\n",
    "    .reduceByKey(lambda a,b: a+b) \\\n",
    "    .sortBy(lambda r: r[1], False)\n",
    "    \n",
    "words_top.take(20)\n",
    "\n",
    "\n",
    "stopw = sc.textFile(\"/??/data/stopwords.txt\").collect()\n",
    "stopw = set(stopw)\n",
    "\n",
    "words_top2 = songsDF2.rdd \\\n",
    "    .flatMap(lambda r: r[5].split(\" \")) \\\n",
    "    .filter(lambda r: len(r)>1) \\\n",
    "    .filter(lambda r: r not in stopw) \\\n",
    "    .map(lambda r: (r, 1)) \\\n",
    "    .reduceByKey(lambda a,b: a+b) \\\n",
    "    .sortBy(lambda r: r[1], False)\n",
    "    \n",
    "words_top2.take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Choose three of your choice from the set of most frequent non-stop-words. Add three columns to the DataFrame (one column for each word) with a True/False flag to indicate whether the word is mentioned at least once in the song.\n",
    "\n",
    "songsDF2 = songsDF2.withColumn('is_love', F.when(F.regexp_extract(songsDF2['text'], r'\\b(love)\\b', 1) == 'love', 1).otherwise(0))\n",
    "songsDF2 = songsDF2.withColumn('is_like', F.when(F.regexp_extract(songsDF2['text'], r'\\b(like)\\b', 1) == 'like', 1).otherwise(0))\n",
    "songsDF2 = songsDF2.withColumn('is_know', F.when(F.regexp_extract(songsDF2['text'], r'\\b(know)\\b', 1) == 'know', 1).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3  For performers with at least 500 songs (see 3.1), find out what proportion of their songs contain the three common words you selected from Assignment 4.2.\n",
    "\n",
    "interprets_words = interprets.join(songsDF2, 'interpret') \\\n",
    "    .select('interpret', 'is_love', 'is_like', 'is_know') \\\n",
    "    .groupBy('interpret') \\\n",
    "    .agg({'is_love':'avg', 'is_like':'avg', 'is_know':'avg'})\n",
    "\n",
    "interprets_words.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "72ce3b0a56a865d480673a9187eace210a751ef3304bdc5d2817c20bdd65e6d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}